{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re \n",
    "\n",
    "#Fonction pour trouver les codes correspondants à un pays entre les codes de pays et le nom des pays :\"\n",
    "def equiv (x):\n",
    "    return(df1[df1['Country Name'] == x]['Country Code'][0])\n",
    "\n",
    "\n",
    "#fonction pour trouver toutes les lignes qui correspondent à un pays où à une variable en particulier\n",
    "\n",
    "def recherche_ligne (x,y,df) :\n",
    "    if x == 'Pays' :\n",
    "        expression = re.compile(y+\".*?;\")\n",
    "        return(list(i[:-1] for i in (expression.findall(';'.join(df.index))))) \n",
    "    else :\n",
    "        expression = re.compile(\".{,4}\"+y+\";\")\n",
    "        return(expression.findall(';'.join(df.index)))\n",
    "\n",
    "#\n",
    "#Si l'utilisateur cherche des lignes en fonction de pays il faut le mettre dans x\n",
    "#\n",
    "#sinon on recherche d'autres caractéristiques (/!\\ il faut entre le nom avec des caractères regex pour les ( et %)\n",
    "#\n",
    "#/!\\ Attention /!\\ : avec cette fonction on renvoit listes de chaines de caractères qui correspondent aux noms des\n",
    "#colonnes + le séparateur qu'on a utilisé \";\" il faut donc le supprimer en ne prenant pas le dernier caractères des\n",
    "#chaines [:,-1]\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On va télécharger les bases de données et repérer les variables pertinentes dans chacune des bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On commmence par créer les dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut légèrement modifier le fichier csv dézippé pour enlever les deux premières lignes, qui ne comprennent que des infos générales sur le format du fichier mais qui entrainaient un problème d'ouverture via la commande pd.read_csv car elles comportaient des virgules.\n",
    "\n",
    "On peut ensuite ouvrir sereinement toutes les base modifiées ainsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_forest = pd.read_csv(\"chiffre_agri_foret_peche.csv\")\n",
    "augment_pib = pd.read_csv(\"chiffre_augment_pib.csv\")\n",
    "energie_utilisee = pd.read_csv(\"chiffre_energie_utilise.csv\")\n",
    "emission_GES = pd.read_csv(\"chiffre_GES_total.csv\")\n",
    "nucle_total = pd.read_csv('chiffre_nucle_total_nuke_total_fossile.csv')\n",
    "part_indus_construc = pd.read_csv('chiffre_part_indus_construc.csv')\n",
    "pib = pd.read_csv(\"chiffre_pib.csv\")\n",
    "nom_pays = pib['Country Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list  = [agri_forest, augment_pib, energie_utilisee, emission_GES, nucle_total, part_indus_construc, pib]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On regarde chaque dataframe pour identifier les variables pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_forest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_pib.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energie_utilisee.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_GES.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucle_total.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_indus_construc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pib.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que tous les df sont construits de la même manière. On a le nom du pays, son abréviation, le nom de l'indicateur utilisé, son code, puis sa valeur pour chaque année. On a aussi toujours une colonne vide, qui ne nous gène pas vraiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On nettoie les bases en enlevant les informations qui ne nous intéresse pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudra enlever la colomne \"unnamed\", les colomnes qui correpondent aux années qui ne nous intéresssent pas, et éventuellement les lignes (=pays ou région) que l'on ne garde pas.\n",
    "\n",
    "Par exemple, conserve-t-on les pays comme Aruba dont on ne connait que le PIB? Je pense que la question elle est vite répondue.\n",
    "\n",
    "Pareil, est-ce que ça a vraiement un intérêt de garder les zones géographiques du type Asie du Sud-Est, etc?  ce ne sont que des aggrégats de pays, donc pas forcément."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On fusionne les dataframe pour aggréger tous ces indicateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut envisager plusieurs manières de fusionner ces df. Soit on a en index Pays_Année et les colomnes correspindent chacune à un indice, soit on a Pays_Indicateur et les colonnes correspondent chacune a une année. Ce sont les formats wide et long (cf tp2).\n",
    "\n",
    "Pour des raisons de lisibilité, il est évident que l'on va conserver le nom de l'indicateur, et non pas son nom de code. En revanche, il faudra voir à l'usage si on préfère utiler le nom complet des pays ou seulement leur nom de code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a ici la syntaxe qui permet de créer une nouvelle colomne en lui domnant le nom que l'on souhaite\n",
    "pib['Pays_indic'] = pib['Country Code'].str[:3] + '_pib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait ici la modif sur tous les df à l'aide d'une boucle for, \n",
    "#mais ça peut donner des noms de variable un peu long à manipuler\n",
    "for df in df_list :\n",
    "    df['Pays_indic'] = df['Country Code'].str[:3] + '_' + df['Indicator Name'].str[:99]\n",
    "#part_indus_construc['Pays_indic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On concatène les df, on les trie et on met en index la variable créée à cet effet ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)\n",
    "df = df.sort_values('Pays_indic').set_index('Pays_indic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des colonnes et lignes inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ici la liste des colonnes que l'on supprimme pour se restreindre aux données qui nous intéressent, sutrement dit à partir de 1980 (je ne sais plsu si on avait dit 1980 ou 1985)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_data_list = ['Unnamed: 65', 'Indicator Code', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', \n",
    "                   '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '2020']\n",
    "df = df.drop(useless_data_list, axis = 1)\n",
    "#df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher à enlever les lignes qui ne contiennent que peu d'infos (au moins 10 valeurs manquantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "nan_dict = {}\n",
    "for i in range(len(df1.index)) :\n",
    "    nb_nan = df1.iloc[i].isnull().sum()\n",
    "    if nb_nan >10 :\n",
    "        nan_dict[list(df.index)[i]] = nb_nan\n",
    "nan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(index = nan_dict.keys(), axis = 0)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant cela, on supprme environ 600 lignes. Pour le rafiner, il faudrait voir si l'on ne doit pas supprimer toutes les données d'un pays lorsque l'on a que des infos sur deux ou trois indicateurs (notamment qi que sur le PIB). On doit pouvoir s'en sortir en supprimant tous les indexs qui commencent par le code du pays détecté de cette manière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Adrien]La fonction pour récupérer les indexs des pays où on a moins de 3 indicateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pays_dic ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nom_pays : \n",
    "    compter_nb_indic = df1.apply(lambda x: True if x['Country Name'] == i else False, axis = 1)\n",
    "    if len(compter_nb_indic[compter_nb_indic == True].index) <3 :\n",
    "        liste_pays_dic[i] = compter_nb_indic[compter_nb_indic == True].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les lignes des pays dont on a trop peu d'indicateurs complet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in liste_pays_dic.keys():\n",
    "    df1 = df1.drop(index = liste_pays_dic[i], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a supprimer en tout 58 lignes. De plus on va aussi supprimer de la base les aggrégats de pays (ces lignes là sont colinéaires aux autres, ce qui risque de nous poser problème plus tard dans la prédiction). Voilà les régions à supprimer : Upper middle income, Latin America & the Caribbean (IDA & IBRD countries),Middle East & North Africa (IDA & IBRD countries),South Asia (IDA & IBRD), Middle East & North Africa (IDA & IBRD countries), Latin America & the Caribbean (IDA & IBRD countries),East Asia & Pacific (IDA & IBRD countries), Europe & Central Asia (IDA & IBRD countries), Sub-Saharan Africa, Sub-Saharan Africa (excluding high income), Post-demographic dividend, Pre-demographic dividend, OECD members, North America, Middle East & North Africa (excluding high income), Middle East & North Africa,Late-demographic dividend, Lower middle income\n",
    "Low & middle income,Latin America & Caribbean,Least developed countries: UN classification, Latin America & Caribbean (excluding high income),IBRD only,IDA & IBRD total,IDA total,IDA blend,Heavily indebted poor countries (HIPC),High income, European Union, Fragile and conflict affected situations,East Asia & Pacific (excluding high income)\n",
    "Early-demographic dividend, East Asia & Pacific, Europe & Central Asia (excluding high income), Europe & Central Asia,Central Europe and the Baltics\n",
    "\n",
    "\n",
    "à propos des aggrégats (comment ils aggrègent :)\n",
    "\n",
    "Aggregation Rules\n",
    "\n",
    "Aggregates are based on the World Bank’s regional and income classification of economies. Because of missing data, aggregates for groups of economies should be treated as approximations of unknown totals or average values. Regional and income group aggregates are based on the largest available set of data. The aggregation rules are intended to yield estimates for a consistent set of economies from one period to the next and for all indicators. Small differences between sums of subgroup aggregates and overall totals and averages may occur because of the approximations used. In addition, compilation errors and data reporting practices may cause discrepancies in theoretically identical aggregates such as world exports and world imports.\n",
    "\n",
    "Five methods of aggregation are used in the World Development Indicators:\n",
    "\n",
    "For group and world totals denoted in the tables by a t, missing data are imputed based on the relationship of the sum of available data to the total in the year of the previous estimate. The imputation process works forward and backward from 2010. Missing values in 2010 are imputed using one of several proxy variables for which complete data are available in that year. The imputed value is calculated so that it (or its proxy) bears the same relationship to the total of available data. Imputed values are usually not calculated if missing data account for more than a third of the total in the benchmark year. The variables used as proxies are GNI in U.S. dollars, total population, exports and imports of goods and services in U.S. dollars, and value added in agriculture, industry, manufacturing, and services in U.S. dollars.\n",
    "\n",
    "Aggregates marked by an s are sums of available data. Missing values are not imputed. Sums are not computed if more than a third of the observations in the series or a proxy for the series are missing in a given year.\n",
    "\n",
    "Aggregates of ratios are generally calculated as weighted averages of the ratios (indicated by w) using the value of the denominator or, in some cases, another indicator as a weight. The aggregate ratios are based on available data, including data for economies not shown in the main tables. Missing values are assumed to have the same average value as the available data. No aggregate is calculated if missing data account for more than a third of the value of weights in the benchmark year. In a few cases the aggregate ratio may be computed as the ratio of group totals after imputing values for missing data according to the above rules for computing totals.\n",
    "\n",
    "Aggregate growth rates are generally calculated as a weighted average of growth rates (and indicated by a w). In a few cases growth rates may be computed from time series of group totals. Growth rates are not calculated if more than half the observations in a period are missing. For further discussion of methods of computing growth rates see below.\n",
    "\n",
    "Aggregates denoted by an m are medians of the values shown in the table. No value is shown if more than half the observations for countries with a population of more than 1 million are missing. Exceptions to the rules occur throughout the book. Depending on the judgment of World Bank analysts, the aggregates may be based on as little as 50 percent of the available data.\n",
    "In other cases, where missing or excluded values are judged to be small or irrelevant, aggregates are based only on the data shown in the tables.\n",
    "\n",
    "Du coup en fonction de comment ils ont agrégés les données ça peut être intéressant ou non de les conserver. Notamment ceux pour lesquels ils ont utilisés la 1ère méthode puisqu'elle nous permet d'avoir une approximation des données qui nous manque (après est ce qu'on veut garder des approximations ? Dans tous les cas il faudra voir je pense si nos prédictions sont robustes à leur ajout ou non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "liste_supression = [\"Upper middle income\", \"Latin America & the Caribbean (IDA & IBRD countries)\",\"Middle East & North Africa (IDA & IBRD countries)\",\"South Asia (IDA & IBRD)\",\"Middle East & North Africa (IDA & IBRD countries)\", \"Latin America & the Caribbean (IDA & IBRD countries)\",\"East Asia & Pacific (IDA & IBRD countries)\",\"Europe & Central Asia (IDA & IBRD countries)\",\"Sub-Saharan Africa\", \"Sub-Saharan Africa (excluding high income)\",\"Post-demographic dividend\", \"Pre-demographic dividend\", \"OECD members\", \"North America\", \"Middle East & North Africa (excluding high income)\", \"Middle East & North Africa\",\"Late-demographic dividend\", \"Lower middle income\",\"Low & middle income\",\"Latin America & Caribbean\",\"Least developed countries: UN classification\", \"Latin America & Caribbean (excluding high income)\",\"IBRD only\",\"IDA & IBRD total\",\"IDA total\",\"IDA blend\",\"Heavily indebted poor countries (HIPC)\",\"High income\",\"European Union\", \"Fragile and conflict affected situations\",\"East Asia & Pacific (excluding high income)\",\"Early-demographic dividend\",\"East Asia & Pacific\",\"Europe & Central Asia (excluding high income)\",\"Europe & Central Asia\",\"Central Europe and the Baltics\"]\n",
    "\n",
    "for i in liste_supression :\n",
    "    df2 = df2.drop(labels = recherche_ligne(\"Pays\",equiv(i),df2), axis = 0)\n",
    "df1 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a supprimer encore en tout une centaine de ligne en supprimant l'ensemble des valeurs agrégées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Début des statistiques descriptives :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé un vecteur temps pour pouvoir créer des graphiques en fonction du temps facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(1980,2019,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur deux subplots différents\n",
    "plt.subplot(211)\n",
    "plt.plot(t[0:31],df1.loc['FRA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T)\n",
    "plt.subplot(212)\n",
    "plt.plot(t[0:31],df1.loc['FRA_GDP growth (annual %)'][2:42].to_numpy()[1:32].T)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Sur le même plot\\n\",\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['FRA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  #  commence un deuxième axe qui partage le même axe x\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('PIB', color=color)  \n",
    "ax2.plot(t[0:31], df1.loc['FRA_GDP (current US$)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur deux subplots différents\n",
    "plt.subplot(211)\n",
    "plt.plot(t[0:31],df1.loc['USA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T)\n",
    "plt.subplot(212)\n",
    "plt.plot(t[0:31],df1.loc['USA_GDP growth (annual %)'][2:42].to_numpy()[1:32].T)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Sur le même plot\\n\",\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['USA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  #  commence un deuxième axe qui partage le même axe x\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('PIB', color=color)  \n",
    "ax2.plot(t[0:31], df1.loc['USA_GDP (current US$)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer un nouvel indicateur qui va nous donner la croissance à l'année des gazs à effet de serre pour chaque pays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in recherche_ligne('','Émissions totales de GES \\(kt d’équivalent CO2\\)',df1) :\n",
    "    df1.loc[i[0:3]+'_croissance émissions GES (kt d’équivalent CO2)'] = df1.loc[i[:-1]][3:44].astype(np.float64).diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on à la croissance des émissions de gazs à effet de serre par an, on peut représenter la croissance du PIB et celle-ci sur le même graphe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur le même plot,\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['USA_croissance émissions GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  #  commence un deuxième axe qui partage le même axe x\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Croissance du PIB', color=color)  \n",
    "ax2.plot(t[0:31], df1.loc['USA_GDP growth (annual %)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a apparemment une certaine concommitance des courbes, cela-dit il faut faire attention aux effets d'échelles car ici le PIB ne passe presque jamais dans le négatif (ce qui est loin d'être le cas de la croissance des émissions de gaz à effet de serre). On va essayer de le faire dans le cas de la France pour se faire plus d'idées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur le même plot,\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['FRA_croissance émissions GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  #  commence un deuxième axe qui partage le même axe x\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Croissance du PIB', color=color)  \n",
    "ax2.plot(t[0:31], df1.loc['FRA_GDP growth (annual %)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle pour effectuer une régression d'une variable sur une autre pour un pays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idée : on pourrait essayer de faire du clustering afin de déterminer la dépendance de la croissance à certains facteurs afin d'essayer de prédire la dépendance de la croissance à l'émission de gaz à effet de serre.\n",
    "\n",
    "Je vais essayer de régresser la croissance du PIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recherche_ligne(\"Pays\",\"FRA\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = df1.loc[['FRA_GDP (current US$)', 'FRA_Émissions totales de GES (kt d’équivalent CO2)']]\n",
    "gdp = pd.DataFrame(test.loc['FRA_GDP (current US$)'][3:30])\n",
    "ges = pd.DataFrame(test.loc['FRA_Émissions totales de GES (kt d’équivalent CO2)'][3:30])\n",
    "gdp = gdp['FRA_GDP (current US$)'].to_numpy(dtype = float)\n",
    "ges = ges['FRA_Émissions totales de GES (kt d’équivalent CO2)'].to_numpy(dtype = float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "def affin(x,a,b): \n",
    "    return a*x + b\n",
    "popt, pcov = scipy.optimize.curve_fit(affin, ges, gdp)\n",
    "coeff, cst = popt[0], popt[1]\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va regarder si ça a du sens sur les USA, où l'on pourra vérifier la pertinence des coefficients obtenus à l'aide des graphiques ci-dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df1.loc[['USA_GDP (current US$)', 'USA_Émissions totales de GES (kt d’équivalent CO2)']]\n",
    "gdp = pd.DataFrame(test.loc['USA_GDP (current US$)'][3:30])\n",
    "ges = pd.DataFrame(test.loc['USA_Émissions totales de GES (kt d’équivalent CO2)'][3:30])\n",
    "gdp = gdp['USA_GDP (current US$)'].to_numpy(dtype = float)\n",
    "ges = ges['USA_Émissions totales de GES (kt d’équivalent CO2)'].to_numpy(dtype = float)\n",
    "\n",
    "popt, pcov = scipy.optimize.curve_fit(affin, gdp, ges)\n",
    "coeff, cst = popt[0], popt[1]\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur le même plot\\n\",\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['USA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.plot(t[0:31], coeff*df1.loc['USA_GDP (current US$)'][2:42].to_numpy()[1:32].T + cst, color='k')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bonne nouvelle, c'est que ça marche bien.\n",
    "La mauvaise nouvelle, c'est que pour une raison inconnue si j'inverse ges et gdp dans la fonction, les résultats qu'il donne sont incohérents : il met que cst=1, autrement dit il se contente de faire une régression de la forme apib = ges. On a alors une approximation très mauvaise, qui ne prend en fait pas en compte la forme du modèle que l'on voulait imposer avec la définition de la fonction affin. Exemple ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = scipy.optimize.curve_fit(affin, ges, gdp)\n",
    "coeff, cst = popt[0], popt[1]\n",
    "print(popt)\n",
    "\n",
    "#Sur le même plot\\n\",\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('time (s)')\n",
    "ax1.set_ylabel('Emission de GES', color=color)\n",
    "ax1.plot(t[0:31], df1.loc['USA_GDP (current US$)'][2:42].to_numpy()[1:32].T, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.plot(t[0:31], coeff*df1.loc['USA_Émissions totales de GES (kt d’équivalent CO2)'][2:42].to_numpy()[1:32].T + cst, color='k')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
