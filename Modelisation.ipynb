{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import sklearn as sklearn\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import geoplot as gplt\n",
    "import geopandas as gpd\n",
    "\n",
    "def refresh_dico(Name,Code,df):\n",
    "    dic = {}\n",
    "    for i in df[[Name,Code]].dropna().drop_duplicates().iterrows() :\n",
    "        dic[i[1][Name]] = i[1][Code]\n",
    "    return (dic)\n",
    "\n",
    "def rech_ligne_pays (y,df) :\n",
    "    expression = re.compile(dic_pays[y]+\".*?;\")\n",
    "    return(list(i[:-1] for i in (expression.findall(';'.join(df.index)+';'))))\n",
    "\n",
    "def rech_ligne_indic (y,df):\n",
    "    expression = re.compile(\".{,4}\"+y+\";\")\n",
    "    return(list(i[:-1] for i in (expression.findall(';'.join(df.index)+';'))))\n",
    "\n",
    "def create_gdf (df_geo,map_monde) :\n",
    "    map_monde_clean = pd.DataFrame()\n",
    "    map_monde_clean[['Country Code','geometry']] = map_monde[['iso_a3','geometry']].dropna()\n",
    "    gdf = gpd.GeoDataFrame(df_geo.dropna().reset_index().merge(map_monde_clean,on = 'Country Code'),\n",
    "                           geometry=df_geo.dropna()\n",
    "                                       .reset_index()\n",
    "                                       .merge(map_monde_clean,on = 'Country Code')['geometry'])\n",
    "    gdf = gdf.reset_index()\n",
    "    gdf = gdf.set_index('Pays_indic')\n",
    "    return(gdf)\n",
    "\n",
    "def log_norm (df_norm) :\n",
    "    return(np.log10(df_norm.astype(np.float64))/np.log10(df_norm.astype(np.float64).max()))\n",
    "\n",
    "def geo_plot (df,indic,annee,couleur = 'Oranges',norm=True) : \n",
    "    #On importe la map monde dans un data frame avec ses données géographiques : \n",
    "    map_monde = gpd.read_file('map_monde (1).json')\n",
    "    #on créé deux dictionnaires différents pour pouvoir adapter les codes pays et merge le plus correctemment possible\n",
    "    #les deux dataframe: \n",
    "    dic_map = refresh_dico('iso_a3','sovereignt',map_monde)\n",
    "    dic_code = refresh_dico('Country Code','Country Name',df)  \n",
    "    liste_non_concord = []\n",
    "    \n",
    "    #On récupère tous les pays pour lesquels les codes pays ne correspondent pas :\n",
    "    for i in dic_map.keys():\n",
    "        j = ''\n",
    "        try :\n",
    "            j = dic_code[i]\n",
    "        except KeyError:\n",
    "            liste_non_concord.append(dic_map[i])\n",
    "\n",
    "    for i in liste_non_concord:\n",
    "        try :\n",
    "            map_monde.loc[map_monde['sovereignt'] == i,'iso_a3'] = dic_pays[i]\n",
    "        except KeyError:\n",
    "            print(i +' n\\'a aucun équivalent dans la table des données')\n",
    "            \n",
    "    #On peut dés maintenant commencer le plot :\n",
    "    ax = gplt.polyplot(map_monde['geometry'],\n",
    "                       edgecolor='None',\n",
    "                       facecolor='lightgray',\n",
    "                       figsize=(18, 7))\n",
    "\n",
    "    gdf = create_gdf(df.loc[rech_ligne_indic(indic,df),['Country Code',annee]],map_monde)\n",
    "    if norm :\n",
    "        gdf[annee] = log_norm(gdf[annee])\n",
    "    gplt.choropleth(gdf,\n",
    "                hue = annee,\n",
    "                cmap = couleur,\n",
    "                #norm=colors.LogNorm(vmin=gdf[annee].min(),\n",
    "                #                    vmax=gdf[annee].max()),\n",
    "                legend=True,\n",
    "                ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Complete_Data.csv\")\n",
    "df1 = df1.set_index('Pays_indic')\n",
    "dic_code = refresh_dico('Country Code','Country Name',df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici une liste des codes de pays, et un dictionnaire avec le nom des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = []\n",
    "for i in df1['Country Code']:\n",
    "    if i not in code_list : \n",
    "        code_list.append(i)\n",
    "code_list.pop(-1)\n",
    "\n",
    "dic = {}\n",
    "dic['pib'] = '_GDP (current US$)'\n",
    "dic['pib_hab'] = '_GDP (current US$) par Tete'\n",
    "dic['pib_growth'] = '_GDP growth (annual %)'\n",
    "dic['pib_hab_growth'] = '_Croissance_GDP (current US$) par Tete (pourcent)'\n",
    "dic['pop'] = '_Population, total'\n",
    "dic['ges'] = '_Émissions totales de GES (kt d’équivalent CO2)'\n",
    "dic['ges_growth'] = '_Croissance_Émissions totales de GES (kt d’équivalent CO2) (pourcent)\t'\n",
    "dic['ges_hab'] = '_Émissions totales de GES (kt d’équivalent CO2) par Tete'\n",
    "dic['ges_hab_growth'] = '_Croissance_Émissions totales de GES (kt d’équivalent CO2) par Tete (pourcent)'\n",
    "dic['industry'] = '_Industry (including construction), value added (% of GDP)'\n",
    "dic['agr'] = '_Agriculture, forestry, and fishing, value added (% of GDP)'\n",
    "dic['clean_nrj'] = '_Alternative and nuclear energy (% of total energy use)'\n",
    "dic['nrj_hab'] = '_Energy use (kg of oil equivalent per capita)'\n",
    "dic['nrj_hab_growth'] = '_Croissance_Energy use (kg of oil equivalent per capita) (pourcent)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher à créer la base avec les données qui nous intéressent pour la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress (country_code, regresseur, regresse) :\n",
    "    \n",
    "    if country_code + regresse in df1.index and country_code + regresseur in df1.index :\n",
    "        interm= pd.DataFrame(df1.loc[[country_code + regresse, country_code + regresseur]]).drop(['Country Name',\n",
    "        'Country Code','Indicator Name'],axis =1).dropna(axis = 1)\n",
    "\n",
    "        if interm.shape != (2,0): \n",
    "            x = sm.add_constant(interm.loc[country_code + regresseur].to_numpy())\n",
    "            y = interm.loc[country_code + regresse].to_numpy()\n",
    "\n",
    "            model = sm.OLS(y,x,'drop')\n",
    "            results = model.fit()\n",
    "\n",
    "            r2 = results.rsquared\n",
    "            coef = results.params[1]\n",
    "\n",
    "            return coef, r2\n",
    "    \n",
    "    else : return\n",
    "    \n",
    "def get_coeff (regresse, regresseur) :    \n",
    "    dico = {}\n",
    "    for code in code_list:\n",
    "        dico[code] = regress(code, regresse, regresseur)\n",
    "        if dico[code] == None:\n",
    "            dico.pop(code)\n",
    "\n",
    "    regress_df = pd.DataFrame(dico.values(), dico.keys(), ['Coefficient de ' + regresse + ' sur ' + regresseur,\n",
    "                                                         'R2 de ' + regresse + ' sur ' + regresseur])\n",
    "    return regress_df\n",
    "\n",
    "\n",
    "def get_2000(var):\n",
    "    dic = {}\n",
    "    \n",
    "    for country_code in code_list : \n",
    "        if country_code + var in df1.index :\n",
    "            dic[country_code] = df1.loc[country_code + var][23]\n",
    "    \n",
    "    temp_df = pd.DataFrame(dic.values(), dic.keys(), ['2000' + var])\n",
    "    \n",
    "    return(temp_df)\n",
    "\n",
    "def get_average_growth_rate(var) :\n",
    "    dic = {}\n",
    "    \n",
    "    for country_code in code_list : \n",
    "        if country_code + var in df1.index :    \n",
    "            values = list(df1.loc[country_code + var][3:])\n",
    "            values = [x for x in values if ~np.isnan(x)]\n",
    "            initial_value = values[0]\n",
    "            final_value = values[len(values)-1]\n",
    "            variation_rate = (100 * ((final_value / initial_value))**(1/len(values))) - 100\n",
    "            if variation_rate != np.inf :\n",
    "                dic[country_code] = variation_rate\n",
    "    \n",
    "    temp_df = pd.DataFrame(dic.values(), dic.keys(), ['Average Growth Rate' + var])\n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c202bd1a7735>:53: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  variation_rate = (100 * ((final_value / initial_value))**(1/len(values))) - 100\n",
      "<ipython-input-4-c202bd1a7735>:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  variation_rate = (100 * ((final_value / initial_value))**(1/len(values))) - 100\n"
     ]
    }
   ],
   "source": [
    "data = get_average_growth_rate(dic['pib_hab'])\n",
    "\n",
    "data_list = [get_average_growth_rate(dic['agr']), get_average_growth_rate(dic['industry']), \n",
    "            get_average_growth_rate(dic['ges_hab']), get_average_growth_rate(dic['clean_nrj']),\n",
    "            get_average_growth_rate(dic['nrj_hab']), \n",
    "            get_2000(dic['pib_hab']), get_2000(dic['agr']), get_2000(dic['industry']),\n",
    "            get_2000(dic['ges_hab']), get_2000(dic['clean_nrj']), get_2000(dic['nrj_hab']), \n",
    "            get_coeff(dic['pib_hab'], dic['ges_hab']), get_coeff(dic['pib_hab_growth'], dic['ges_hab_growth']),\n",
    "            get_coeff(dic['pib_hab'], dic['nrj_hab']), get_coeff(dic['pib_hab_growth'], dic['nrj_hab_growth'])]\n",
    "for i in data_list :\n",
    "    data = data.merge(i, how = 'outer', left_index = True, right_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.dropna(axis = 0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0307882345c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mNorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "Norm = StandardScaler()\n",
    "Norm.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = Norm.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test2).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.DataFrame()\n",
    "for i in test.columns :\n",
    "    test2[i] = preprocessing.scale(test[i])\n",
    "test2.index = test.index\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iner = []\n",
    "for k in range(2,50):\n",
    "    result = pd.DataFrame()\n",
    "    result=test2.copy()\n",
    "    centroid, result['Cluster'], inertie = sklearn.cluster.k_means(test2, k)\n",
    "    #nb_gens_cluster = []\n",
    "    #nb_gens = len(result.index)\n",
    "    #iner_inter = 0\n",
    "    #for i in range(0,k-1):\n",
    "    #    result.loc['Centroid '+str(i)] = np.concatenate((centroid[i],np.array([i])))\n",
    "    #    result.where(result['Cluster'] == i).dropna()\n",
    "    #    nb_gens_cluster.append(len(result.where(result['Cluster'] == i).dropna().index))\n",
    "    #    iner_inter += (nb_gens_cluster[i]/nb_gens) *np.linalg.norm(centroid[i],ord =2)\n",
    "    iner.append(inertie)\n",
    "plt.plot(np.linspace(2,50,num=48),iner)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(2,4,num=3),iner[:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''nb_gens_cluster = []\n",
    "nb_gens = len(result.index)\n",
    "iner_inter = 0\n",
    "for i in range(0,k-1):\n",
    "    print(centroid[i])\n",
    "    print(centroid[i].shape)\n",
    "    print(np.array([i]).shape)\n",
    "    #result.loc['Centroid '+str(i)] = np.concatenate((centroid[i],np.array([i])))\n",
    "    result.where(result['Cluster'] == i).dropna()\n",
    "    nb_gens_cluster.append(len(result.where(result['Cluster'] == i).dropna().index))\n",
    "    iner_inter += (nb_gens_cluster[i]/nb_gens) *np.linalg.norm(centroid[i],ord =2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA(2)\n",
    "PCA.fit(test2)\n",
    "print(PCA.singular_values_)\n",
    "print(PCA.explained_variance_ratio_*100)\n",
    "test3 = PCA.transform(test2)\n",
    "#plt.plot(t,PCA.explained_variance_ratio_*100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ACP = pd.DataFrame(test3)\n",
    "result_ACP.head()\n",
    "result_ACP.index = result[:-k+1].index\n",
    "result_ACP['Cluster'] = result['Cluster'][:-k+1]\n",
    "result_ACP.head(150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = np.array(['black','red','royalblue','forestgreen','maroon','gold','darkgoldenrod','deeppink','mediumturquoise','orange','firebrick','silver'])\n",
    "plt.scatter(result_ACP[0].to_numpy(),result_ACP[1].to_numpy(),c = colormap[result_ACP['Cluster'].astype(int).to_numpy()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(1,20,num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
